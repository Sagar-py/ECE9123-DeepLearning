{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGnlRWvkY-2c"
   },
   "source": [
    "# Homework Assignment - 4\n",
    "\n",
    "## Question 4\n",
    "\n",
    "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmj22-TcZMef"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3608,
     "status": "ok",
     "timestamp": 1617426150763,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Kj_7Tz0-pK69"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6367,
     "status": "ok",
     "timestamp": 1617426158034,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Jjsbi1u3QFEM",
    "outputId": "5efe0a7a-6457-45a5-bceb-934a86938606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 2.0MB 8.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.2MB 51.2MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1617426872036,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "S3isCn_MFSR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from transformers import BertModel\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1617432306357,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "XrXoYksxMnml"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1617426182832,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "AJqoaFpVpoM8",
    "outputId": "353fcbfa-6467-4d33-ab94-45f3bfc179e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.7.10\n",
      "IPython version      : 5.5.0\n",
      "\n",
      "numpy       : 1.19.5\n",
      "pandas      : 1.1.5\n",
      "torch       : 1.8.1+cu101\n",
      "transformers: 4.4.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufzPdoTtNikq"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Download the Google Play app reviews dataset using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1995,
     "status": "ok",
     "timestamp": 1617426187758,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "SgPRhuMzi9ot",
    "outputId": "1c97af15-c8f5-4857-bf50-5daaf9620bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
      "To: /content/apps.csv\n",
      "100% 134k/134k [00:00<00:00, 48.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
      "To: /content/reviews.csv\n",
      "7.17MB [00:00, 43.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
    "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7GO8vXo6IVO"
   },
   "source": [
    "Here is how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1617426203289,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "mUKLyKc7I6Qp",
    "outputId": "dbf54a19-9619-4972-8e5f-ac74a6d45212"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrew Thomas</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
       "      <td>Update: After getting a response from the deve...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4.17.0.3</td>\n",
       "      <td>2020-04-05 22:25:57</td>\n",
       "      <td>According to our TOS, and the term you have ag...</td>\n",
       "      <td>2020-04-05 15:10:24</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Craig Haines</td>\n",
       "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
       "      <td>Used it for a fair amount of time without any ...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.17.0.3</td>\n",
       "      <td>2020-04-04 13:40:01</td>\n",
       "      <td>It sounds like you logged in with a different ...</td>\n",
       "      <td>2020-04-05 15:11:35</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>steven adkins</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
       "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.17.0.3</td>\n",
       "      <td>2020-04-01 16:18:13</td>\n",
       "      <td>This sounds odd! We are not aware of any issue...</td>\n",
       "      <td>2020-04-02 16:05:56</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lars Panzerbjørn</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
       "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>4.17.0.2</td>\n",
       "      <td>2020-03-12 08:17:34</td>\n",
       "      <td>We do offer this option as part of the Advance...</td>\n",
       "      <td>2020-03-15 06:20:13</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scott Prewitt</td>\n",
       "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
       "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>4.17.0.2</td>\n",
       "      <td>2020-03-14 17:41:01</td>\n",
       "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
       "      <td>2020-03-15 23:45:51</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userName  ...      appId\n",
       "0     Andrew Thomas  ...  com.anydo\n",
       "1      Craig Haines  ...  com.anydo\n",
       "2     steven adkins  ...  com.anydo\n",
       "3  Lars Panzerbjørn  ...  com.anydo\n",
       "4     Scott Prewitt  ...  com.anydo\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AiAdQ3j6SDe"
   },
   "source": [
    "Let's first check the size of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1617426242813,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "dB2jE6am7Dpo",
    "outputId": "eab2e0de-9b3b-4936-cc21-c12ddbf27f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15746\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q1. How many samples are there in this dataset? \n",
    "\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1617426407247,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Wwh_rW4Efhs3",
    "outputId": "c3ef9d7a-877b-49fa-ac3e-d9bbd38448aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common score is 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
    "\n",
    "plt.hist(df.score)\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('frequency')\n",
    "print(\"Most common score is\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZM0GKviobjM"
   },
   "source": [
    "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1617426413904,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "ei0xmdi1Chp0"
   },
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "  rating = int(rating)\n",
    "  if rating <= 2:\n",
    "    return 0\n",
    "  elif rating == 3:\n",
    "    return 1\n",
    "  else: \n",
    "    return 2\n",
    "\n",
    "df['sentiment'] = df.score.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1617426414834,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "V-155O-SFSqE"
   },
   "outputs": [],
   "source": [
    "class_names = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1617426431256,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "y3tY3ECJDPaz",
    "outputId": "a00cab63-40bf-44e9-b03a-dad355e06e3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5028.,    0.,    0.,    0.,    0., 5042.,    0.,    0.,    0.,\n",
       "        5676.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
    "\n",
    "plt.hist(df.sentiment, label= class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aHyGuTFgyPO"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1617426435898,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "E7Mj-0ne--5t"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "c8fd763139264b28841055bfeb51b1ca",
      "159b3b6107284359be8685c261add5b2",
      "80a419ef5b964e08a21f0207af664c7c",
      "5c4172c408604957b567e0c3b7a241d4",
      "6da8619517b8482d9c6a51fc07a9b041",
      "3bee41fca6184ac7a3ec08c8998d8963",
      "dab09410c5a84d11a6c1291b878f0233",
      "4e26e9dac9694b3786385b230e92b4ea",
      "6382938d83264b1db081cb735bcdf693",
      "80ca5af530be4bd397def8b742fbc8ef",
      "1379aabfe18f404fab3e8c8228331153",
      "52e3cac42b1644bab60b50054589af05",
      "dffab536650d490788018f0502faeb13",
      "4b8d1d86595941a5b903ddd43cdb637a",
      "868f6afb1b27480bbfd0da0b6f4915a0",
      "361037c5e3314a5bbb4022f81453e763",
      "ab362ccccbf1428eb25d49dba826351b",
      "a02ff8834fc9455f9a85c763faba318f",
      "e9d84f97bc6e4c5087d1c9b8199c7eae",
      "0bd9870ac0b14e2dacedb7b4cafa4065",
      "1e8a05889b2f419891cb6b069a9f2fab",
      "6e53eebf61ef47cf811ae7a4d56e3da6",
      "bc5a2f2778a342979f6f86b474c44105",
      "5411ac7525184316a3a80131b95a702d"
     ]
    },
    "executionInfo": {
     "elapsed": 2720,
     "status": "ok",
     "timestamp": 1617426439362,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "H3AfJSZ8NNLF",
    "outputId": "34e9c2f3-e8ca-4966-b5e4-b2ba41233e1d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fd763139264b28841055bfeb51b1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6382938d83264b1db081cb735bcdf693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab362ccccbf1428eb25d49dba826351b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfrSbwTQ-wi_"
   },
   "source": [
    "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1617426440782,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "HZMitwrqm2eb"
   },
   "outputs": [],
   "source": [
    "sample_txt = 'Every day feels like the same during the lock down.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1617426458423,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "iTFhpHpsoWO7",
    "outputId": "0712b97c-9f46-47e4-8d12-fab8d6f59789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
      "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
    "\n",
    "tokens= tokenizer.tokenize(sample_txt)\n",
    "print(tokens)\n",
    "token_ids= tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9ap7jdL0LYU"
   },
   "source": [
    "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1617426462928,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Vea9edaaxSPO",
    "outputId": "a8a027cb-bc60-46a9-c1da-fdfbd5f77d72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS69c8WvdOED"
   },
   "source": [
    "The token ids are now stored in a Tensor and padded to a length of 32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1617426468245,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "YzBmcOla0yQR",
    "outputId": "6d527002-7770-4da1-84f8-e4cfece9d5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
       "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itAyVPsNdyc1"
   },
   "source": [
    "The attention mask has the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1617426470052,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Wiv5LLiw03Ox",
    "outputId": "31f0b530-2ffc-42d0-d6b6-87a9e858b9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['attention_mask'][0]))\n",
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1RvhC4jNHHy"
   },
   "source": [
    "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1617426548254,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "IagGoafKLUwW",
    "outputId": "84da47b1-2920-46eb-b0c6-064825f19fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q5. Invert the encoded token ids.\n",
    "invert_tokens =  tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "print(invert_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW6ajl30t6du"
   },
   "source": [
    "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1617426551891,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "t7xSmJtLuoxW"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvvcoU6nurHy"
   },
   "source": [
    "# Building the dataset\n",
    "\n",
    "Let's now create a dataset using the tokenizer. Here is some code that does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1617426555873,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "E2BPgRJ7YBK0"
   },
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2uwsvCYqDJK"
   },
   "source": [
    "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1617433198260,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "B-vWzoo81dvO",
    "outputId": "ff1a3387-20f3-4a58-975c-cc247d7c256d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14170, 12) (788, 12) (788, 12)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q6. Create three data frames: df_train, df_val, df_train as above and print their shapes.\n",
    "\n",
    "df_train1, df_test= train_test_split(df, test_size=0.05)\n",
    "df_train, df_val= train_test_split(df_train1, test_size=0.05263)\n",
    "\n",
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4tQ1x-vqNab"
   },
   "source": [
    "We also need to create a couple of data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1617427023766,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "KEGqcvkuOuTX"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.content.to_numpy(),\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1617427024756,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "vODDxMKsPHqI",
    "outputId": "46c0e696-71d1-4d9b-df02-d43658ad5ea7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6dlOptwqlhF"
   },
   "source": [
    "Let's have a look at an example batch from our training data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1617427026153,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Y93ldSN47FeT",
    "outputId": "639a794b-12b1-43d2-f2ee-1d49d4eb7707"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 160])\n",
      "torch.Size([16, 160])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()\n",
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "440Nd31VTHER"
   },
   "source": [
    "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 3263,
     "status": "ok",
     "timestamp": 1617427030738,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "0P41FayISNRI"
   },
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFE7YSbFdY4t"
   },
   "source": [
    "And encode our sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1617427034629,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "s1aoFxbQSn15"
   },
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'], \n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLLu8zmqbaHV"
   },
   "source": [
    "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1617427051408,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "mUJHXNpIbcci",
    "outputId": "1c3bf2a8-3ebc-4db4-b4e9-ea80e3bcea31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# TODO: Q7. Print the sizes of the hidden states and the pooled output.\n",
    "\n",
    "print(len(last_hidden_state)) \n",
    "print(len(pooled_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o_NiS3WgOFf"
   },
   "source": [
    "We can use all of this knowledge to create a classifier that uses the BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1617427082510,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "m_mRflxPl32F"
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME,return_dict = False)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJg8m3NQJahc"
   },
   "source": [
    "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 14015,
     "status": "ok",
     "timestamp": 1617427128057,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "i0yQnuSFsjDp"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCPCFDLlKIQd"
   },
   "source": [
    "We'll move the example batch of our training data to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1617427140141,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "mz7p__CqdaMO"
   },
   "outputs": [],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hr1EgkEtKOIB"
   },
   "source": [
    "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1617427142709,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "2rTCj46Zamry",
    "outputId": "d9730506-f23c-4009-9855-80258c5181ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3667, 0.3875, 0.2458],\n",
       "        [0.4513, 0.2976, 0.2511],\n",
       "        [0.4222, 0.2626, 0.3152],\n",
       "        [0.3998, 0.2818, 0.3183],\n",
       "        [0.2722, 0.4380, 0.2898],\n",
       "        [0.5963, 0.1957, 0.2079],\n",
       "        [0.4070, 0.2777, 0.3153],\n",
       "        [0.4183, 0.3288, 0.2529],\n",
       "        [0.2683, 0.3602, 0.3715],\n",
       "        [0.4586, 0.2818, 0.2596],\n",
       "        [0.4676, 0.2418, 0.2907],\n",
       "        [0.4276, 0.3481, 0.2243],\n",
       "        [0.3975, 0.2828, 0.3197],\n",
       "        [0.4794, 0.2431, 0.2775],\n",
       "        [0.3272, 0.3103, 0.3624],\n",
       "        [0.3041, 0.2749, 0.4209]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(input_ids, attention_mask), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9xikRdtRN1N"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76g7FV85H-T8"
   },
   "source": [
    "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1617427149282,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "5v-ArJ2fCCcU"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8522g7JIu5J"
   },
   "source": [
    "\n",
    "Let's continue with writing a helper function for training our model for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1617427221227,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "bzl9UhuNx1_Q"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
    "    \n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device) \n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4PniYIte0fr"
   },
   "source": [
    "Let's write another function that helps us evaluate the model on a given data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1617427455192,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "CXeRorVGIKre"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).\n",
    "    \n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device) \n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_rdSDBHhhCh"
   },
   "source": [
    "Using those two, we can write our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2068712,
     "status": "ok",
     "timestamp": 1617429676821,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "1zhHoFNsxufs",
    "outputId": "6f4237b4-76c8-4688-9949-e3531933c8da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.7356017599424713 accuracy 0.6656316160903317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.5804714962840081 accuracy 0.7538071065989848\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.42440733684407667 accuracy 0.8400846859562456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.4956962388381362 accuracy 0.8185279187817258\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.2307982091049813 accuracy 0.9270995059985886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.4909455148782581 accuracy 0.8553299492385786\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.14757165490582894 accuracy 0.9568807339449542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.581008961526677 accuracy 0.8591370558375634\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.11645558438008666 accuracy 0.9669724770642203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.5889394129044376 accuracy 0.8756345177664974\n",
      "\n",
      "CPU times: user 18min 28s, sys: 15min 46s, total: 34min 15s\n",
      "Wall time: 34min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
    "\n",
    "  train_acc, train_loss = train_epoch(model,train_data_loader,loss_fn,optimizer,device,scheduler,len(df_train))\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(model,val_data_loader,loss_fn,device,len(df_val) )\n",
    "\n",
    "  print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r8-5zWsiVur"
   },
   "source": [
    "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
    "\n",
    "Plot train and validation accuracy as a function of epoch count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1617431677440,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "-FWG7kBm372V",
    "outputId": "3ec2f32e-f94c-40af-c760-b0f06743e98c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Q11. Plot train/validation accuracies.\n",
    "\n",
    "plt.plot(history['train_acc'], label='Training accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsHqkLAuf8pv"
   },
   "source": [
    "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3HZb3NWFtFf"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "So how good is our model on predicting sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdQ7-ylCj8Gd"
   },
   "source": [
    "We'll define a helper function to get the predictions from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1617431701931,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "EgR6MuNS8jr_"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkbnBTI7kd_y"
   },
   "source": [
    "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7829,
     "status": "ok",
     "timestamp": 1617431712365,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "zHdPZr60-0c_",
    "outputId": "1bc437a2-204f-4cbb-e603-fd792d08f0ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFAekw3mmWUi"
   },
   "source": [
    "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1617432471797,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "6d1qxsc__DTh",
    "outputId": "51f77288-7a74-49f5-9f43-1f6616701b9f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews.\n",
    "\n",
    "cmat = confusion_matrix(y_test, y_pred)\n",
    "df_cmat = pd.DataFrame(cmat, index=class_names, columns=class_names)\n",
    "hmap = sns.heatmap(df_cmat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), ha='right')\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), ha='right')\n",
    "\n",
    "plt.xlabel('Predicted sentiment');\n",
    "plt.ylabel('True sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WL5pDmvFyaU"
   },
   "source": [
    "### Predicting on Raw Text\n",
    "\n",
    "Let's use our model to predict the sentiment of some raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1617432474154,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "QEPi7zQRsDhH"
   },
   "outputs": [],
   "source": [
    "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et8xlDrKpH60"
   },
   "source": [
    "Use your trained model to predict the sentiment expressed in `review_text`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1617432582296,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "Qr_t3rUksumr",
    "outputId": "3fb2f9ad-3e0b-4cc6-fa8d-4ddef02a6ed7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
    "\n",
    "encoding = tokenizer.encode_plus(\n",
    "  review_text,\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1617432737093,
     "user": {
      "displayName": "Ayesha Nazneen Ahmed",
      "photoUrl": "",
      "userId": "04971699396884141521"
     },
     "user_tz": 240
    },
    "id": "KddIlvKqftFI",
    "outputId": "d3f6f206-b594-4951-bb58-7db4bd61b299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: I love Deep Learning! Best course evah!!!1!!\n",
      "Sentiment  : positive\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoding['input_ids'].to(device)\n",
    "attention_mask = encoding['attention_mask'].to(device)\n",
    "outputs = model(input_ids, attention_mask)\n",
    "_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {class_names[prediction]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "file_path='...'\n",
    "\n",
    "def load_emnist(file_path)\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xts, ... = load_emnist(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf39tauBa2V2"
   },
   "source": [
    "## References\n",
    "\n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
    "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
    "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
    "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
    "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
    "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw4prob3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bd9870ac0b14e2dacedb7b4cafa4065": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5411ac7525184316a3a80131b95a702d",
      "placeholder": "​",
      "style": "IPY_MODEL_bc5a2f2778a342979f6f86b474c44105",
      "value": " 436k/436k [00:00&lt;00:00, 1.27MB/s]"
     }
    },
    "1379aabfe18f404fab3e8c8228331153": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b8d1d86595941a5b903ddd43cdb637a",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dffab536650d490788018f0502faeb13",
      "value": 29
     }
    },
    "159b3b6107284359be8685c261add5b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e8a05889b2f419891cb6b069a9f2fab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "361037c5e3314a5bbb4022f81453e763": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bee41fca6184ac7a3ec08c8998d8963": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b8d1d86595941a5b903ddd43cdb637a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e26e9dac9694b3786385b230e92b4ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52e3cac42b1644bab60b50054589af05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_361037c5e3314a5bbb4022f81453e763",
      "placeholder": "​",
      "style": "IPY_MODEL_868f6afb1b27480bbfd0da0b6f4915a0",
      "value": " 29.0/29.0 [00:00&lt;00:00, 36.2B/s]"
     }
    },
    "5411ac7525184316a3a80131b95a702d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c4172c408604957b567e0c3b7a241d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e26e9dac9694b3786385b230e92b4ea",
      "placeholder": "​",
      "style": "IPY_MODEL_dab09410c5a84d11a6c1291b878f0233",
      "value": " 213k/213k [00:01&lt;00:00, 197kB/s]"
     }
    },
    "6382938d83264b1db081cb735bcdf693": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1379aabfe18f404fab3e8c8228331153",
       "IPY_MODEL_52e3cac42b1644bab60b50054589af05"
      ],
      "layout": "IPY_MODEL_80ca5af530be4bd397def8b742fbc8ef"
     }
    },
    "6da8619517b8482d9c6a51fc07a9b041": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6e53eebf61ef47cf811ae7a4d56e3da6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80a419ef5b964e08a21f0207af664c7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bee41fca6184ac7a3ec08c8998d8963",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6da8619517b8482d9c6a51fc07a9b041",
      "value": 213450
     }
    },
    "80ca5af530be4bd397def8b742fbc8ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "868f6afb1b27480bbfd0da0b6f4915a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a02ff8834fc9455f9a85c763faba318f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab362ccccbf1428eb25d49dba826351b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9d84f97bc6e4c5087d1c9b8199c7eae",
       "IPY_MODEL_0bd9870ac0b14e2dacedb7b4cafa4065"
      ],
      "layout": "IPY_MODEL_a02ff8834fc9455f9a85c763faba318f"
     }
    },
    "bc5a2f2778a342979f6f86b474c44105": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8fd763139264b28841055bfeb51b1ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80a419ef5b964e08a21f0207af664c7c",
       "IPY_MODEL_5c4172c408604957b567e0c3b7a241d4"
      ],
      "layout": "IPY_MODEL_159b3b6107284359be8685c261add5b2"
     }
    },
    "dab09410c5a84d11a6c1291b878f0233": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dffab536650d490788018f0502faeb13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e9d84f97bc6e4c5087d1c9b8199c7eae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e53eebf61ef47cf811ae7a4d56e3da6",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e8a05889b2f419891cb6b069a9f2fab",
      "value": 435797
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
